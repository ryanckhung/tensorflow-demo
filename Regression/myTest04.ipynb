{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(3,)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "observations = 1000\n",
    "x1 = np.random.uniform(-10, 10, (observations,1))\n",
    "x2 = np.random.uniform(-10, 10, (observations,1))\n",
    "x3 = np.random.uniform(-10, 10, (observations,1))\n",
    "x = np.column_stack([x1,x2,x3])\n",
    "\n",
    "w = np.array([2,3,4])\n",
    "w = w.T\n",
    "\n",
    "b = 5\n",
    "\n",
    "# flatten() change the shape form (100,1) [matrix] to (100,) [vector]\n",
    "noise = np.random.uniform(-1, 1, (observations,1)).flatten()\n",
    "\n",
    "y = (np.dot(x,w) + b) + noise\n",
    "\n",
    "print(x.shape)\n",
    "print(w.shape)\n",
    "print(noise.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples_count = observations\n",
    "train_samples_count = int(0.8*observations)\n",
    "validation_samples_count = int(0.1*observations)\n",
    "test_samples_count = total_samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = x[:train_samples_count]\n",
    "train_targets = y[:train_samples_count]\n",
    "\n",
    "validation_inputs = x[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = y[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = x[train_samples_count+validation_samples_count:]\n",
    "test_targets = y[train_samples_count+validation_samples_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "8/8 - 0s - loss: 293.3861 - val_loss: 140.1513\n",
      "Epoch 2/10000\n",
      "8/8 - 0s - loss: 84.3932 - val_loss: 27.4977\n",
      "Epoch 3/10000\n",
      "8/8 - 0s - loss: 31.2633 - val_loss: 11.7764\n",
      "Epoch 4/10000\n",
      "8/8 - 0s - loss: 12.2442 - val_loss: 5.4343\n",
      "Epoch 5/10000\n",
      "8/8 - 0s - loss: 5.8351 - val_loss: 1.5359\n",
      "Epoch 6/10000\n",
      "8/8 - 0s - loss: 2.8221 - val_loss: 1.1288\n",
      "Epoch 7/10000\n",
      "8/8 - 0s - loss: 1.1816 - val_loss: 1.4657\n",
      "Epoch 8/10000\n",
      "8/8 - 0s - loss: 0.8625 - val_loss: 0.8001\n",
      "Epoch 9/10000\n",
      "8/8 - 0s - loss: 0.5995 - val_loss: 0.6021\n",
      "Epoch 10/10000\n",
      "8/8 - 0s - loss: 0.4970 - val_loss: 0.4395\n",
      "Epoch 11/10000\n",
      "8/8 - 0s - loss: 0.4107 - val_loss: 0.3687\n",
      "Epoch 12/10000\n",
      "8/8 - 0s - loss: 0.3669 - val_loss: 0.3276\n",
      "Epoch 13/10000\n",
      "8/8 - 0s - loss: 0.3463 - val_loss: 0.3311\n",
      "Epoch 14/10000\n",
      "8/8 - 0s - loss: 0.3433 - val_loss: 0.3329\n",
      "Epoch 15/10000\n",
      "8/8 - 0s - loss: 0.3445 - val_loss: 0.3265\n",
      "Epoch 16/10000\n",
      "8/8 - 0s - loss: 0.3497 - val_loss: 0.3559\n",
      "Epoch 17/10000\n",
      "8/8 - 0s - loss: 0.3488 - val_loss: 0.3327\n",
      "Epoch 18/10000\n",
      "8/8 - 0s - loss: 0.3634 - val_loss: 0.3419\n",
      "Epoch 19/10000\n",
      "8/8 - 0s - loss: 0.3497 - val_loss: 0.3374\n",
      "Epoch 20/10000\n",
      "8/8 - 0s - loss: 0.3519 - val_loss: 0.3748\n",
      "Epoch 21/10000\n",
      "8/8 - 0s - loss: 0.3655 - val_loss: 0.3471\n",
      "Epoch 22/10000\n",
      "8/8 - 0s - loss: 0.3547 - val_loss: 0.3399\n",
      "Epoch 23/10000\n",
      "8/8 - 0s - loss: 0.3474 - val_loss: 0.3356\n",
      "Epoch 24/10000\n",
      "8/8 - 0s - loss: 0.3502 - val_loss: 0.3260\n",
      "Epoch 25/10000\n",
      "8/8 - 0s - loss: 0.3465 - val_loss: 0.3336\n",
      "Epoch 26/10000\n",
      "8/8 - 0s - loss: 0.3523 - val_loss: 0.3686\n",
      "Epoch 27/10000\n",
      "8/8 - 0s - loss: 0.3549 - val_loss: 0.3757\n",
      "Epoch 28/10000\n",
      "8/8 - 0s - loss: 0.3638 - val_loss: 0.3456\n",
      "Epoch 29/10000\n",
      "8/8 - 0s - loss: 0.3649 - val_loss: 0.3528\n",
      "Epoch 30/10000\n",
      "8/8 - 0s - loss: 0.3779 - val_loss: 0.3564\n",
      "Epoch 31/10000\n",
      "8/8 - 0s - loss: 0.3824 - val_loss: 0.3505\n",
      "Epoch 32/10000\n",
      "8/8 - 0s - loss: 0.3593 - val_loss: 0.3355\n",
      "Epoch 33/10000\n",
      "8/8 - 0s - loss: 0.3464 - val_loss: 0.3401\n",
      "Epoch 34/10000\n",
      "8/8 - 0s - loss: 0.3520 - val_loss: 0.3405\n",
      "Epoch 35/10000\n",
      "8/8 - 0s - loss: 0.3549 - val_loss: 0.3371\n",
      "Epoch 36/10000\n",
      "8/8 - 0s - loss: 0.3557 - val_loss: 0.3322\n",
      "Epoch 37/10000\n",
      "8/8 - 0s - loss: 0.3711 - val_loss: 0.3306\n",
      "Epoch 38/10000\n",
      "8/8 - 0s - loss: 0.3967 - val_loss: 0.4080\n",
      "Epoch 39/10000\n",
      "8/8 - 0s - loss: 0.3762 - val_loss: 0.3281\n",
      "Epoch 40/10000\n",
      "8/8 - 0s - loss: 0.3610 - val_loss: 0.3465\n",
      "Epoch 41/10000\n",
      "8/8 - 0s - loss: 0.3449 - val_loss: 0.3530\n",
      "Epoch 42/10000\n",
      "8/8 - 0s - loss: 0.3552 - val_loss: 0.3350\n",
      "Epoch 43/10000\n",
      "8/8 - 0s - loss: 0.3595 - val_loss: 0.3511\n",
      "Epoch 44/10000\n",
      "8/8 - 0s - loss: 0.3510 - val_loss: 0.3280\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.0083203],\n",
      "       [3.0038278],\n",
      "       [4.002934 ]], dtype=float32), array([4.994357], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# in this example the equation is y = x1w1 + x2w2 + x3w3 + b + noise\n",
    "# if hidden_layer_size = 3 will give 3 weights and bias\n",
    "# if hidden_layer_size = 5 will give 5 weights and bias (which make the prediction equation more complicated than original)\n",
    "# for this kind of equation, use 1 layer is good enough\n",
    "input_size = 3\n",
    "output_size = 1\n",
    "hidden_layer_size = 3\n",
    "model_number = 1\n",
    "\n",
    "layer0 = tf.keras.layers.Dense(units=hidden_layer_size, activation=tf.keras.activations.relu)\n",
    "layer1 = tf.keras.layers.Dense(units=output_size)\n",
    "\n",
    "if model_number == 1:\n",
    "    model = tf.keras.Sequential([layer1])\n",
    "else:\n",
    "    model = tf.keras.Sequential([layer0, layer1])\n",
    "\n",
    "opt1 = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "opt2 = tf.keras.optimizers.Adam(1)\n",
    "\n",
    "# metrics=['accuracy'] should be used in classification but not regression\n",
    "# because the results of regression is hard to exact match, therefore accuracy always give 0\n",
    "# for classifcation between cat and dog can give accuracy, because you will only output cat and dog but not something in between\n",
    "#model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer=opt2)\n",
    "\n",
    "\n",
    "\n",
    "# https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n",
    "# For Batch Gradient Descent => batch_size = size of training set\n",
    "# For Stochastic Gradient Descent => Set batch_size=1\n",
    "# for Mini-batch Gradient Descent => Set 1 < batch_size < size of traing set\n",
    "\n",
    "# We can divide the dataset of 2000 examples into batches of 500 then it will take 4 iterations to complete 1 epoch.\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 10000\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size=batch_size, \n",
    "          epochs=max_epochs, \n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets), \n",
    "          verbose = 2 \n",
    "          )  \n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "weights = layer1.get_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3440\n",
      "0.3439992070198059\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_inputs, test_targets)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95.14517]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[10,10,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
